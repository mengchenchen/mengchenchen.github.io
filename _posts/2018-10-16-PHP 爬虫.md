---
title: 记一次 PHP 爬虫
subtitle: 打开了新世界的大门！
tag: PHP
---

<style>

code {
white-space: normal;
}

</style>

## 介绍

> **HOST** : http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/

* 省级行政单位  `HOST + /年份/`

* 市级行政单位  `HOST + /年份/省份 id.html`

* 县级行政单位  `HOST + /年份/省份 id/城市 id.html`

* 镇级行政单位  `HOST + /年份/省份 id/城市 id/县区 id.html`

**注**：年份目前最高 2017 

### 2018年 10 月 19 日最后一次更新（全自动化智能阶段）

* [点击下载 simple_html_dom  ](https://sourceforge.net/projects/simplehtmldom/files/)

* 无需任何人工操作，实现完全自动化

```php
<?php

require_once('./simple_html_dom.php');

// 第一次请求失败
$errors = [];

$host = 'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2017/';
if (!$provinces_html = file_get_html("$host"))
	die($host . ' 这个页面获取失败');
foreach ($provinces_html->find('.provincetr td a') as $province)
	start($host . $province->href);
while (count($errors)) {
	foreach ($errors as $url)
		start($url);
}

/**
 * 开始爬取
 *
 * @param $url
 * @author mengchenchen
 */
function start($url)
{
	global $errors;
	echo $url . PHP_EOL;
	$host = 'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2017/';
	if (!$str = curl_get_contents($url)) {
		$errors[] = $url;
		return;
	}
	$html = str_get_html($str);
	foreach (['citytr', 'countytr', 'towntr'] as $class) {
		switch ($class) {
			case 'citytr':
				if ($html->find(".{$class} td"))
					repeated($host, $html->find(".{$class} td"), 2);
				break;
			case 'countytr':
				$element = $html->find(".{$class} td a", 0);
				if ($element)
					$host = 'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2017/' . substr($element->innertext, 0, 2) . '/';
				repeated($host, $html->find(".{$class} td"), 4);
				break;
			case 'towntr':
				if ($html->find(".{$class} td"))
					repeated($host, $html->find(".{$class} td"), 6, false);
				break;
		}
	}
	if (in_array($url, $errors)) {
		array_splice($errors, array_search($url, $errors), 1);
	}
}

/**
 * 遍历所有页面
 *
 * @param $host
 * @param $element
 * @param $length
 * @param bool $is_jump
 * @author mengchenchen
 */
function repeated($host, $element, $length, $is_jump = true)
{
	foreach ($element as $key => $value) {
		$content = $value->find('a', 0) ? $value->find('a', 0)->innertext : $value->innertext;
		if (in_array(iconv('gbk', 'UTF-8', $content), ['统计用区划代码', '名称']))
			continue;
		$sql = '';
		if ($key % 2 == 0) {
			$content = iconv('gbk', 'UTF-8', $content);
			$sql     .= "set @fid = (select fid FROM citys WHERE entity_id = " . substr($content, 0, $length) . ");";
			$sql     .= "update fbfirste_citys set code = '" . $content . "' where f_title = '";
		} else {
			$content = iconv('gbk', 'UTF-8', $content);
			$sql     .= $content . "' and f_up = @fid;" . PHP_EOL;
		}
		file_put_contents('./txt/sqlsql.sql', $sql, FILE_APPEND);
	}
	if ($is_jump) {
		foreach ($element as $key => $value) {
			if ($value->find('a', 0) && ctype_digit($value->find('a', 0)->innertext)) {
				start($host . $value->find('a', 0)->href);
			}
		}
	}
}

/**
 * 发送请求获取网页
 * 用来代替 file_get_contents ，[响应速度更快，更稳定，自定义错误]
 *
 * @param $url
 * @return mixed
 * @author mengchenchen
 */
function curl_get_contents($url)
{
	$ip                         = '1.1.1.1';
	$ipArr                      = explode(".", $ip);
	$ipArr[3]                   = rand(1, 255);
	$ipArr[2]                   = rand(1, 255);
	$ipArr[1]                   = rand(1, 255);
	$ipArr[0]                   = rand(1, 255);
	$ip                         = implode(".", $ipArr);
	$headers['CLIENT-IP']       = $ip;
	$headers['X-FORWARDED-FOR'] = $ip;
	$headerArr                  = [];
	foreach ($headers as $n => $v) {
		$headerArr[] = $n . ':' . $v;
	}
	$ch = curl_init();
	curl_setopt($ch, CURLOPT_URL, $url);            //设置访问的url地址
	curl_setopt($ch, CURLOPT_HTTPHEADER, $headerArr);
	curl_setopt($ch, CURLOPT_HEADER, 1);
	curl_setopt($ch, CURLOPT_TIMEOUT, 5);           //设置超时
	curl_setopt($ch, CURLOPT_USERAGENT, 'Baiduspider + (+http://www.baidu.com/search/spider.htm)');   //用户访问代理 User-Agent
	curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 1);    //跟踪301
	curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);    //返回结果
	$res = curl_exec($ch);
	curl_close($ch);
	return $res;
}
```

----



### 2018 年 10 月 17 日更新 （半自动化阶段）

进行了一个下午的努力，使用了完全不同的方法，速度更快，结构更清晰，更智能。

* 主要引进了 `simple_html_dom` 操作 HTML 元素
* 错误处理更进一步
* 减少人工操作的步骤
* 知道了 cmd 和文本的换行不是 \r\n 而是直接换行

上代码：

```php
require_once('./simple_html_dom.php');
$countys = require('./countys.php');
foreach ($countys as $num => $item) {
	$url = 'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2017/' . $item['province_id'] . '/' . $item['page'] . '/' . $item['county_id'] . '.html';
	$str = @file_get_contents($url);
	if (!$str) {
		file_put_contents('towns.txt', $url. '这个页面获取失败' . '
', FILE_APPEND);
		continue;
	}
	$html = str_get_html("$str");
	foreach ($html->find('.towntable tr td') as $key => $article) {
		if ($article->find('a', 0)) {
			echo 'this->' . $item['code'] . ' 
';
			file_put_contents('towns.txt', iconv('GBK', 'UTF-8', $article->find('a', 0)->innertext()) . '
', FILE_APPEND);
		}
	}
}
```

* [php函数file_get_contents与curl效率及稳定性问题](https://www.cnblogs.com/devcjq/articles/5347470.html)
* [php 的爬虫经验分享](https://www.v2ex.com/t/324309)
* [服务器反爬虫攻略](https://zhangge.net/4458.html)
* [python解决网站的反爬虫策略总结](https://edu.aliyun.com/a/3915?spm=5176.11310711.0.0.6PF9sD)
* [php爬虫抓取信息及反爬虫相关](https://blog.csdn.net/wustzbq0713/article/details/46276335)
* [爬虫进阶：反反爬虫技巧](https://www.cnblogs.com/zxcv1234/p/9756220.html)
* https://github.com/FantasticLBP/Anti-WebSpider
* [爬虫入门到精通-开始爬虫之旅](https://segmentfault.com/a/1190000009002375)

三个概念：

1. 爬虫（我获取你的数据）
2. 反爬虫（禁止你获取我的数据）
3. 反反爬虫（加了限制你也无法阻止我获取你的数据）
4. ...

**真的是道高一尺魔高一丈！**

分割线下面是之前的老办法

-----



### 代码 （智障阶段）

CGI 模式第一行前加入

```php
header("Content-type: text/html; charset=utf-8");
date_default_timezone_set('PRC');
set_time_limit(0);                  
ini_set('memory_limit', '13312M');   
ini_set('user_agent', 'Baiduspider+(+http://www.baidu.com/search/spider.htm)');
```

CLI 模式

```php
$provinces = [
	['province_id' => 11, 'name' => '北京市'],
    ...
];
$citys     = [
	['province_id' => 11, 'city_id' => 1101, 'code' => '110100000000', 'name' => '市辖区'],
    ...
];
$countys   = [
	['province_id' => '11', 'city_id' => '1101', 'page' => '01', 'county_id' => '110101', 'code' => '110101000000', 'name' => '东城区'],
    ...
];
foreach ($countys as $num => $item) {
	$url = 'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2017/' . $item['province_id'] . '/' . $item['page'] . '/' . $item['county_id'] . '.html';
	// $url   = 'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2017/' . $item['province_id'] . '/' . $item['city_id'] . '.html';
	// $url   = 'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2017/' . $item['province_id'] . '.html';
	$str   = @file_get_contents($url);
	$str   = str_replace([" ", "　", "\t", "\n", "\r"], '', $str);
	$table = str_replace(['</td></tr></table>', '<td>', '</td>', '<tr>', '</tr>'], '', $str);
	$table = str_replace(['</td><td>', '<ahref=\''], '<br>', $table);
	echo 'this->' . $item['code'] . ' ^ ';
	file_put_contents('stats_gov.html', $table, FILE_APPEND);
}
```

### 抓取

#### 省级行政单位

打开页面，审查元素选中表格，复制 HTML 到 Sublime 进行处理。

数据大概如下：

```php
['province_id' => 11, 'name' => '北京市'],

['province_id' => 12, 'name' => '天津市'],

['province_id' => 13, 'name' => '河北省'],

.......

['province_id' => 36, 'name' => '江西省'],

['province_id' => 37, 'name' => '山东省'],

['province_id' => 41, 'name' => '河南省'],

.......
```

#### 市级、县级行政单位

相比『省级行政单位』在一个页面，『市级、县级行政单位』则需要每次打开省份进入新的页面，这个时候就需要借助程序了。

**这里踩过的坑必须要记录下（重点）**

##### 请求超时

- WEB CGI 模式：在发送请求的时候超过 30 秒则报错。

```php 
set_time_limit(0);                              
ini_set('memory_limit', '13312M');  
```

- PHP CLI 模式：使用命令行模式则不会发生超时且 CLI 不需要依赖 apache，速度更快

##### 页面乱码

- WEB CGI 模式：直接 echo 中文会出现乱码

```php
header("Content-type: text/html; charset=utf-8");
```

- PHP CLI 模式：这里需要使用

##### 不稳定出现

```php
ini_set('user_agent', 'Baiduspider+(+http://www.baidu.com/search/spider.htm)');
@file_get_contents($url)
```

##### 获取『县级行政区域』数据量大直接 500

直接改为 cli 命令行模式运行。

直接使用 echo 大量数据，cmd 无法显示全部：解决办法把循环中的数据写入一个文件，echo 当前 item 选项查看进度。

